{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f61ade8",
   "metadata": {},
   "source": [
    "# Parsing av vedtakstekster\n",
    "\n",
    "Vedtakene i tekstkorpuset må parses, dvs. vi må identifisere strukturen i vedtakene, og dele opp vedtakene i deres ulike deler. Formålet er å analysere korpuset, og å legge til rette for å en variert testing opp mot språkmodellen. Eksempelvis ønsker vi å teste ut semantiske søk der vi bare søker i klagers anførsler. Da kan vi etterpå bruke nemndas vurdering fra de samme vedtakene som kontekst opp mot språkmodellen. Et annet bruksområde er i identifisere vedtak der nemnda deler seg i et flertall og et mindretall. Da er det viktig å først identifisere hvilken del av vedtaket som er nemndas vurdering. \n",
    "\n",
    "## Analyse av strukturen i vedtakstekstene\n",
    "Det ser ut til at mange vedtak har samme struktur: sammendrag, dato, saksnr. og tjenesteyter, så klagers anførsler, tjenesteyters anførsler og til slutt nemndas bemerkninger. Før vi går i gang med selve parsingen, skal vi analysere strukturen vedtakene. Hvilke overskrifter bruker vedtakene, har vedtakene de sammen overkriftene? Hva er de stabile strukturene vi kan basere oss på når vi skal parse teksten vedtakene?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5c8d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identifiserte tekstlinjer med uthevet tekst:\n",
      "--------------------------------------------\n",
      "Vedtak i Transportklagenemnda - Fly\n",
      "Sammendrag\n",
      "Dato\n",
      "Saksnummer\n",
      "Tjenesteytere\n",
      "Klager har i det vesentlige anført\n",
      "Tjenesteyterne har i det vesentlige anført\n",
      "Nemnda bemerker\n",
      "Vedtak\n",
      "Nemndas representanter\n",
      "\n",
      "Totalt 10 overskrifter.\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTTextLine, LTChar\n",
    "\n",
    "def extract_text_with_font(pdf_path):\n",
    "    text_info = []\n",
    "\n",
    "    for page_layout in extract_pages(pdf_path):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                for text_line in element:\n",
    "                    if isinstance(text_line, LTTextLine):\n",
    "                        # Attempt to find the first character in the line\n",
    "                        first_char = next((char for char in text_line if isinstance(char, LTChar)), None)\n",
    "                        \n",
    "                        if first_char is not None:\n",
    "                            # Check if the first character is bold\n",
    "                            is_bold = \"Bold\" in first_char.fontname\n",
    "\n",
    "                            # If the first character is bold, consider the entire line bold\n",
    "                            if is_bold:\n",
    "                                text_info.append({\n",
    "                                    \"text\": text_line.get_text(),  # Get the entire line text\n",
    "                                    \"font_name\": first_char.fontname,\n",
    "                                    \"size\": first_char.size,\n",
    "                                    \"is_bold\": is_bold  # This key is optional but can be useful for clarity\n",
    "                                })\n",
    "\n",
    "    return text_info\n",
    "\n",
    "def main(pdf_path):\n",
    "    teller = 0\n",
    "    text_info = extract_text_with_font(pdf_path)\n",
    "\n",
    "    print(\"\\nIdentifiserte tekstlinjer med uthevet tekst:\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    for info in text_info:\n",
    "        print(info[\"text\"].strip())  # This will print each bold line as a separate string\n",
    "        teller +=1\n",
    "    print(\"\\nTotalt\", teller, (\"overskrifter.\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"./pdfs_small/2021-01885.pdf\"  # replace with your PDF file path\n",
    "    main(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504005c",
   "metadata": {},
   "source": [
    "Koden finner det vi forventer. Den har identifisert alle overskrifter og utelatt annen tekst. Dette var for et enkelt vedtak. For å undersøke videre om denne metoden er robust, tester vi på alle vedtak. Det gir ikke mening å printe ut alle overskrifter for 7827 vedtak. Vi leter derfor igjennom tekstlinjer med fet font og tar vare på alle unike tekstlinjer vi finner. Det skal da gi alle overskrifter som er brukt i vedtakene. Om metoden plukker med noe mer, vil vi også se det. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49705b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified lines with bold text:\n",
      "--------------------------------------------\n",
      "Tjenesteyter følger ikke vedtaket i saken (30.03.2023)\n",
      "Dato\n",
      "Tjenesteyter følger ikke vedtaket i saken (28.09.2022)\n",
      "Tjenesteytere\n",
      "Tjenesteyter følger ikke vedtaket i saken (01.11.2022)\n",
      "Vedtak i Transportklagenemnda - Fly\n",
      "Tjenesteyter følger ikke vedtaket i saken (20.09.2019)\n",
      "Tjenesteyter følger ikke vedtaket i saken (15.08.2023)\n",
      "Vedtak i Pakkereisenemnda\n",
      "Tjenesteyter følger ikke vedtaket i saken (21.12.2022)\n",
      "Tjenesteyter følger ikke vedtaket i saken (16.04.2020)\n",
      "Klager har i det vesentlige anført\n",
      "Tjenesteyter følger ikke vedtaket i saken (11.10.2022)\n",
      "Tjenesteyter følger ikke vedtaket i saken (10.01.2023)\n",
      "Vedtak i Transportklagenemnda - Sjø\n",
      "Tjenesteyter følger ikke vedtaket i saken (21.08.2017)\n",
      "Tjenesteyter følger ikke vedtaket i saken (20.09.2022)\n",
      "Tjenesteyter følger ikke vedtaket i saken (06.07.2023)\n",
      "Sammendrag\n",
      "Tjenesteyter følger ikke vedtaket i saken (13.03.2023)\n",
      "Nemndas representanter\n",
      "Tjenesteyter følger ikke vedtaket i saken (29.11.2022)\n",
      "- Kollektivreiser\n",
      "Tjenesteyter følger ikke vedtaket i saken (23.05.2023)\n",
      "Vedtak i Transportklagenemnda\n",
      "Tjenesteyter følger ikke vedtaket i saken (12.01.2023)\n",
      "Tjenesteyterne har i det vesentlige anført\n",
      "Vedtak\n",
      "Tjenesteyter følger ikke vedtaket i saken (31.01.2023)\n",
      "Tjenesteyter følger ikke vedtaket i saken (27.06.2023)\n",
      "Saksnummer\n",
      "Tjenesteyter følger ikke vedtaket i saken (18.04.2023)\n",
      "Tjenesteyter følger ikke vedtaket i saken (12.09.2023)\n",
      "Tjenesteyter følger ikke vedtaket i saken (08.02.2023)\n",
      "Tjenesteyter følger ikke vedtaket i saken (07.06.2023)\n",
      "Nemnda bemerker\n",
      "Tjenesteyter følger ikke vedtaket i saken (13.01.2021)\n",
      "Tjenesteyter følger ikke vedtaket i saken (09.11.2022)\n",
      "Tjenesteyter følger ikke vedtaket i saken (21.02.2023)\n",
      "Tjenesteyter følger ikke vedtaket i saken (02.03.2023)\n",
      "Tjenesteyter følger ikke vedtaket i saken (12.07.2023)\n",
      "\n",
      "Total unique bold lines found: 41\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTTextLine, LTChar\n",
    "\n",
    "def extract_text_with_font(pdf_path):\n",
    "    text_info = []\n",
    "\n",
    "    for page_layout in extract_pages(pdf_path):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                for text_line in element:\n",
    "                    if isinstance(text_line, LTTextLine):\n",
    "                        # Attempt to find the first character in the line\n",
    "                        first_char = next((char for char in text_line if isinstance(char, LTChar)), None)\n",
    "\n",
    "                        if first_char is not None:\n",
    "                            # Check if the first character is bold\n",
    "                            is_bold = \"Bold\" in first_char.fontname\n",
    "\n",
    "                            # If the first character is bold, consider the entire line bold\n",
    "                            if is_bold:\n",
    "                                text_info.append(text_line.get_text().strip())  # Get the entire line text\n",
    "\n",
    "    return text_info\n",
    "\n",
    "def main(directory_path):\n",
    "    bold_lines_set = set()\n",
    "\n",
    "    # Loop through every file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            full_path = os.path.join(directory_path, filename)\n",
    "            # Extract the bold lines from the current PDF and add them to the set\n",
    "            bold_lines = extract_text_with_font(full_path)\n",
    "            for line in bold_lines:\n",
    "                bold_lines_set.add(line)\n",
    "\n",
    "    print(\"\\nIdentified lines with bold text:\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    for line in bold_lines_set:\n",
    "        print(line)  # This will print each unique bold line as a separate string\n",
    "\n",
    "    print(\"\\nTotal unique bold lines found:\", len(bold_lines_set))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_path = \"./pdfs/\"  # replace with your directory path\n",
    "    main(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9dc61e",
   "metadata": {},
   "source": [
    "Resultatet er betryggende. Vi får et begrenset antall overskrifter. Mange av er variasjoner av samme med et tillegg av en dato. Her kan vi med tanke på parsingen fjerne datoen slik at alle disse blir like. Etter å ha fjernet variasjonen med dato, står vi igjen med 15 ulike overskrifter. Fire av disse er hovedoverskrifter på vedtakene:\n",
    "- Vedtak i Pakkereisenemnda\n",
    "- Vedtak i Transportklagenemnda - Fly\n",
    "- Vedtak i Transportklagenemnda - Sjø\n",
    "- Vedtak i Transportklagenemnda - Kollektivreiser\n",
    "I pdf-en er overskriften til Transportklagenemnda - Kollektivreiser delt over to linjer. Derfor kommer den opp både som \"Transportklagenemnda\" og som \"- Kollektivreiser\".\n",
    "\n",
    "For å vite om det er variasjon mellom vedtakene i bruken av overskrifter, dvs. om alle overskrifter er med i alle vedtak, kjører vi en sjekk også på dette. Vi lagrer da alle overskrifter for et vedtak i en liste og sjekker hvor mange forskellige lister vi får."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78faab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTTextLine, LTChar\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_text_with_font(pdf_path):\n",
    "    text_info = []\n",
    "\n",
    "    for page_layout in extract_pages(pdf_path):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextContainer):\n",
    "                for text_line in element:\n",
    "                    if isinstance(text_line, LTTextLine):\n",
    "                        first_char = next((char for char in text_line if isinstance(char, LTChar)), None)\n",
    "\n",
    "                        if first_char is not None and \"Bold\" in first_char.fontname:\n",
    "                            text_info.append(text_line.get_text().strip())\n",
    "\n",
    "    return text_info\n",
    "\n",
    "def main(directory_path):\n",
    "    all_pdfs_bold_lines = []\n",
    "    list_occurrences = defaultdict(int)\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            full_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "\n",
    "            bold_lines = extract_text_with_font(full_path)\n",
    "            if bold_lines:  # Only add non-empty lists\n",
    "                # Convert list to a tuple so it can be hashed for the dictionary of occurrences\n",
    "                bold_lines_tuple = tuple(bold_lines)\n",
    "                all_pdfs_bold_lines.append(bold_lines_tuple)\n",
    "                list_occurrences[bold_lines_tuple] += 1\n",
    "\n",
    "    unique_lists = set(all_pdfs_bold_lines)\n",
    "\n",
    "    print(\"\\nNumber of unique lists: \", len(unique_lists))\n",
    "    for unique_list in unique_lists:\n",
    "        print(\"\\nItems in the unique list:\")\n",
    "        for item in unique_list:\n",
    "            print(item)\n",
    "        print(\"Number of PDFs with this unique list: \", list_occurrences[unique_list])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory_path = \"./pdfs\"  # replace with your directory path\n",
    "    main(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f78109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
